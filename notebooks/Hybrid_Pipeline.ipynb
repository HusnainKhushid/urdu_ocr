{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Spell Checker Pipeline\n",
    "\n",
    "This notebook implements and evaluates a multi-stage spell correction pipeline as requested:\n",
    "\n",
    "1.  **KNN**: For Candidate Generation (Recall).\n",
    "2.  **Logistic Regression**: For Candidate Selection/Re-ranking (Precision).\n",
    "3.  **Naive Bayes**: For Prior Probability scoring.\n",
    "\n",
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T08:33:32.579008Z",
     "iopub.status.busy": "2025-12-13T08:33:32.578743Z",
     "iopub.status.idle": "2025-12-13T08:33:34.087696Z",
     "shell.execute_reply": "2025-12-13T08:33:34.086963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 154781 unique words.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Setup paths\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.knn_correction import KNNSpellChecker\n",
    "\n",
    "DATA_PATH = '../data/urdu_words.txt'\n",
    "\n",
    "# Load Word List (Language Model)\n",
    "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "    words = f.read().split()\n",
    "    \n",
    "WORD_COUNTS = Counter(words)\n",
    "TOTAL_WORDS = sum(WORD_COUNTS.values())\n",
    "VOCAB = list(WORD_COUNTS.keys())\n",
    "\n",
    "def get_prior(word):\n",
    "    return WORD_COUNTS[word] / TOTAL_WORDS\n",
    "\n",
    "print(f\"Loaded {len(VOCAB)} unique words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KNN Model (Candidate Generator)\n",
    "We use our pre-implemented KNN model to find the top Candidates efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T08:33:34.119067Z",
     "iopub.status.busy": "2025-12-13T08:33:34.118742Z",
     "iopub.status.idle": "2025-12-13T08:33:34.158132Z",
     "shell.execute_reply": "2025-12-13T08:33:34.157359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading KNN SpellChecker from data/urdu_words.txt.knn.pkl...\n",
      "KNN Loaded. Vocabulary size: 154781\n"
     ]
    }
   ],
   "source": [
    "knn = KNNSpellChecker(literature_path=DATA_PATH, k=1)\n",
    "\n",
    "def get_knn_candidates(typo, n=50):\n",
    "    if not knn.fitted: return []\n",
    "    try:\n",
    "        vec = knn.vectorizer.transform([typo])\n",
    "        dists, idxs = knn.knn.kneighbors(vec, n_neighbors=n)\n",
    "        candidates = []\n",
    "        for i in range(len(idxs[0])):\n",
    "            idx = idxs[0][i]\n",
    "            word = knn.words_list[idx]\n",
    "            candidates.append((word, dists[0][i])) # (candidate, cosine_dist)\n",
    "        return candidates\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Logistic Regression (Candidate Selector)\n",
    "We need to train a binary classifier to decide if a `(Typo, Candidate)` pair is a \"Match\" (1) or \"Not Match\" (0).\n",
    "\n",
    "### Feature Engineering\n",
    "Features for the classifier:\n",
    "1. **Edit Distance**: Levenshtein distance.\n",
    "2. **KNN Distance**: Cosine distance from vector space.\n",
    "3. **Length Diff**: Abs diff in lengths.\n",
    "4. **Start Match**: 1 if first char matches, else 0.\n",
    "5. **End Match**: 1 if last char matches, else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T08:33:34.160184Z",
     "iopub.status.busy": "2025-12-13T08:33:34.159987Z",
     "iopub.status.idle": "2025-12-13T08:33:34.165229Z",
     "shell.execute_reply": "2025-12-13T08:33:34.164628Z"
    }
   },
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "def extract_features(typo, candidate, knn_dist):\n",
    "    features = []\n",
    "    # 1. Edit Dist\n",
    "    ed = levenshtein(typo, candidate)\n",
    "    features.append(ed)\n",
    "    # 2. KNN Dist\n",
    "    features.append(knn_dist)\n",
    "    # 3. Length Diff\n",
    "    features.append(abs(len(typo) - len(candidate)))\n",
    "    # 4. Start Match\n",
    "    features.append(1 if typo and candidate and typo[0] == candidate[0] else 0)\n",
    "    # 5. End Match\n",
    "    features.append(1 if typo and candidate and typo[-1] == candidate[-1] else 0)\n",
    "    return features\n",
    "\n",
    "def generate_typo(word):\n",
    "    # (Same noise function as before)\n",
    "    if len(word) < 2: return word\n",
    "    urdu_chars = 'ابپتٹثجچحخدڈذرڑزژسشصضطظعغفقکگلمنںوہیے'\n",
    "    op = random.choice(['insert', 'delete', 'replace', 'transpose'])\n",
    "    word = list(word)\n",
    "    idx = random.randint(0, len(word) - 1)\n",
    "    if op == 'insert': word.insert(idx, random.choice(urdu_chars))\n",
    "    elif op == 'delete': word.pop(idx)\n",
    "    elif op == 'replace': word[idx] = random.choice(urdu_chars)\n",
    "    elif op == 'transpose' and idx < len(word)-1: word[idx], word[idx+1] = word[idx+1], word[idx]\n",
    "    return \"\".join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T08:33:34.166805Z",
     "iopub.status.busy": "2025-12-13T08:33:34.166646Z",
     "iopub.status.idle": "2025-12-13T08:35:13.510552Z",
     "shell.execute_reply": "2025-12-13T08:35:13.510009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data for LR model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 10000 samples. Positives: 880\n"
     ]
    }
   ],
   "source": [
    "# Generate Training Data for Logistic Regression\n",
    "print(\"Generating training data for LR model...\")\n",
    "random.seed(42)\n",
    "TRAIN_SIZE = 1000\n",
    "train_words = [w for w in VOCAB if len(w) > 3]\n",
    "samples = random.sample(train_words, min(TRAIN_SIZE, len(train_words)))\n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for truth in samples:\n",
    "    typo = generate_typo(truth)\n",
    "    # Get KNN candidates\n",
    "    candidates = get_knn_candidates(typo, n=10)\n",
    "    \n",
    "    has_truth = False\n",
    "    for cand_word, cand_dist in candidates:\n",
    "        label = 1 if cand_word == truth else 0\n",
    "        feats = extract_features(typo, cand_word, cand_dist)\n",
    "        X_data.append(feats)\n",
    "        y_data.append(label)\n",
    "        if label == 1: has_truth = True\n",
    "    \n",
    "    # If truth wasn't in top 10, maybe add it explicitly as a positive sample?\n",
    "    # (Optional, but helps recall if KNN is poor. But we want to model the pipeline)\n",
    "\n",
    "print(f\"Training Data: {len(X_data)} samples. Positives: {sum(y_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T08:35:13.512664Z",
     "iopub.status.busy": "2025-12-13T08:35:13.512504Z",
     "iopub.status.idle": "2025-12-13T08:35:13.536616Z",
     "shell.execute_reply": "2025-12-13T08:35:13.536039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Trained.\n",
      "Coefficients: [[-1.85467689 -1.35281612 -3.36916467  1.49038142  1.45819938]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/husnainkhurshid/Projects/ML/venv/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/husnainkhurshid/Projects/ML/venv/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/husnainkhurshid/Projects/ML/venv/lib/python3.14/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_data)\n",
    "\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "clf.fit(X_scaled, y_data)\n",
    "\n",
    "print(\"Logistic Regression Trained.\")\n",
    "print(\"Coefficients:\", clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Full Pipeline Execution\n",
    "Now we combine it ALL.\n",
    "$$ Score(c) = P_{LR}(Correct | Features) \\times P_{Prior}(c) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T08:35:13.538243Z",
     "iopub.status.busy": "2025-12-13T08:35:13.538108Z",
     "iopub.status.idle": "2025-12-13T08:35:13.541720Z",
     "shell.execute_reply": "2025-12-13T08:35:13.541117Z"
    }
   },
   "outputs": [],
   "source": [
    "def hybrid_correction(typo):\n",
    "    # 1. KNN Candidates\n",
    "    candidates = get_knn_candidates(typo, n=50)\n",
    "    if not candidates: return typo\n",
    "    \n",
    "    # 2. Extract Features for all candidates\n",
    "    feats_batch = []\n",
    "    cand_words = []\n",
    "    for c_word, c_knn_dist in candidates:\n",
    "        feats = extract_features(typo, c_word, c_knn_dist)\n",
    "        feats_batch.append(feats)\n",
    "        cand_words.append(c_word)\n",
    "        \n",
    "    # 3. Logistic Regression Scores (Probabilities)\n",
    "    X_batch = scaler.transform(feats_batch)\n",
    "    # predict_proba returns [prob_0, prob_1]\n",
    "    lr_probs = clf.predict_proba(X_batch)[:, 1] \n",
    "    \n",
    "    # 4. Naive Bayes Combination\n",
    "    best_score = -1\n",
    "    best_word = typo\n",
    "    \n",
    "    for i, prob in enumerate(lr_probs):\n",
    "        cand = cand_words[i]\n",
    "        prior = get_prior(cand)\n",
    "        if prior == 0: prior = 1e-10 # Smoothing\n",
    "        \n",
    "        # Final Score: LR_Likelihood * Prior\n",
    "        # (Using relatively high weight on LR prob)\n",
    "        final_score = prob * prior\n",
    "        \n",
    "        if final_score > best_score:\n",
    "            best_score = final_score\n",
    "            best_word = cand\n",
    "            \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation (500 Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T08:35:13.543092Z",
     "iopub.status.busy": "2025-12-13T08:35:13.542985Z",
     "iopub.status.idle": "2025-12-13T08:36:03.609283Z",
     "shell.execute_reply": "2025-12-13T08:36:03.608547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 500 unseen test words...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid Pipeline Accuracy: 69.40%\n",
      "Time taken: 50.06s\n",
      "Average latency: 100.12ms\n"
     ]
    }
   ],
   "source": [
    "# Generate TEST set (different seed)\n",
    "random.seed(101)\n",
    "TEST_SIZE = 500\n",
    "test_samples = random.sample(train_words, min(TEST_SIZE, len(train_words)))\n",
    "test_set = [(generate_typo(w), w) for w in test_samples]\n",
    "\n",
    "print(f\"Evaluating on {len(test_set)} unseen test words...\")\n",
    "\n",
    "correct_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for typo, truth in test_set:\n",
    "    pred = hybrid_correction(typo)\n",
    "    if pred == truth:\n",
    "        correct_count += 1\n",
    "\n",
    "duration = time.time() - start_time\n",
    "acc = (correct_count / len(test_set)) * 100\n",
    "\n",
    "print(f\"\\nHybrid Pipeline Accuracy: {acc:.2f}%\")\n",
    "print(f\"Time taken: {duration:.2f}s\")\n",
    "print(f\"Average latency: {(duration/len(test_set))*1000:.2f}ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
