{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Hybrid Spell Checker Pipeline\n",
                "\n",
                "This notebook demonstrates the **Hybrid Spell Checker** integrated into the project.\n",
                "\n",
                "## Architecture\n",
                "The pipeline consists of three stages:\n",
                "1.  **Candidate Generation (Recall)**: Uses **KNN** on character N-Grams to find the top 50 similar words in vector space.\n",
                "2.  **Candidate Ranking (Precision)**: Uses a **Logistic Regression** classifier trained to distinguish optimal candidates based on features like *Edit Distance*, *Vector Distance*, and *Length Difference*.\n",
                "3.  **Final Selection**: Combines the Logistic Regression score with the **Naive Bayes** prior (Word Frequency) to select the best correction.\n",
                "\n",
                "$$ Score(c) = P_{LR}(Correct | Features) \\times P_{Prior}(c) $$\n",
                "\n",
                "## 1. Setup & Import"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import random\n",
                "import time\n",
                "\n",
                "# Add project root to path to import src modules\n",
                "sys.path.append(os.path.abspath('..'))\n",
                "\n",
                "from src.spell_checkers import HybridCorrector\n",
                "\n",
                "DATA_PATH = '../data/urdu_words.txt'\n",
                "\n",
                "print(\"Import Successful. Initializing HybridCorrector...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Initialization & Training\n",
                "The `HybridCorrector` handles its own training and caching. On the first run, it will:\n",
                "1. Load the Urdu dictionary.\n",
                "2. Train the KNN Index.\n",
                "3. Generate synthetic training data (typos).\n",
                "4. Train the Logistic Regression classifier.\n",
                "5. Save everything to `data/urdu_words.txt.hybrid.pkl`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "start_time = time.time()\n",
                "corrector = HybridCorrector(DATA_PATH, cache_dir='../data')\n",
                "print(f\"Model Ready in {time.time() - start_time:.2f}s\")\n",
                "\n",
                "# Check internal state\n",
                "print(f\"Dictionary Size: {len(corrector.lm_words)}\")\n",
                "print(f\"Logistic Regression Classes: {corrector.clf.classes_}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Interactive Demonstration\n",
                "Let's test single corrections."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "typos = ['کتاپ', 'لیکھن', 'مشینے', 'اردو']\n",
                "\n",
                "print(f\"{'Typo':<15} -> {'Correction':<15}\")\n",
                "print(\"-\" * 35)\n",
                "for t in typos:\n",
                "    corr = corrector.correct(t)\n",
                "    print(f\"{t:<15} -> {corr:<15}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation on Synthetic Data\n",
                "We generate 500 random typos from the dictionary and measure the accuracy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_typo(word):\n",
                "    if len(word) < 2: return word\n",
                "    urdu_chars = 'ابپتٹثجچحخدڈذرڑزژسشصضطظعغفقکگلمنںوہیے'\n",
                "    op = random.choice(['insert', 'delete', 'replace', 'transpose'])\n",
                "    word = list(word)\n",
                "    idx = random.randint(0, len(word) - 1)\n",
                "    if op == 'insert': word.insert(idx, random.choice(urdu_chars))\n",
                "    elif op == 'delete': word.pop(idx)\n",
                "    elif op == 'replace': word[idx] = random.choice(urdu_chars)\n",
                "    elif op == 'transpose' and idx < len(word)-1: word[idx], word[idx+1] = word[idx+1], word[idx]\n",
                "    return \"\".join(word)\n",
                "\n",
                "# Sample 500 words\n",
                "random.seed(101)\n",
                "valid_words = [w for w in corrector.lm_words.keys() if len(w) > 3]\n",
                "test_set = [(generate_typo(w), w) for w in random.sample(valid_words, 500)]\n",
                "\n",
                "print(f\"Evaluating on {len(test_set)} words...\")\n",
                "\n",
                "correct_count = 0\n",
                "start = time.time()\n",
                "\n",
                "for typo, truth in test_set:\n",
                "    pred = corrector.correct(typo)\n",
                "    if pred == truth:\n",
                "        correct_count += 1\n",
                "\n",
                "duration = time.time() - start\n",
                "acc = (correct_count / len(test_set)) * 100\n",
                "\n",
                "print(f\"\\nHybrid Pipeline Accuracy: {acc:.2f}%\")\n",
                "print(f\"Total Time: {duration:.2f}s\")\n",
                "print(f\"Average Latency: {(duration/len(test_set))*1000:.2f}ms\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}